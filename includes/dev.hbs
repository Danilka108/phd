<hgroup>
    <h2 id="chapter_dev">Разработка подистемы управления</h2>
    <hgroup>
        <h3 id="chapter_dev_section_arch" id="arch_desc">Архитектура подсистемы управления
        </h3>
        <p>На основе требований, сформулированных в первой главе, была выбрана архитектура, обеспечивающая автономное
            функционирование, централизованное управление и воспроизводимое развертывание компонентов системы СКУД в
            изолированной среде.</p>

        <p>Разработанная архитектура, представленная на <a class="link" href="#arch">рисунке</a>, включает
            управляющий модуль — менеджер, размещаемые
            на управляемых устройствах агенты, а также контроллеры сервисов, отвечающие за реализацию операций
            жизненного цикла. Менеджер координирует состояние всех сервисов в кластере, инициирует выполнение
            управляющих сценариев и взаимодействует с агентами, формируя агрегированную картину состояния системы. Агент
            управляет установленными на устройстве сервисами, отслеживает их работоспособность, обменивается данными с
            менеджером и запускает контроллеры, каждый из которых реализует операции установки, запуска, остановки и
            удаления конкретного сервиса. Менеджер может располагаться как на отдельном управляющем устройстве, так и на
            одном из управляемых.</p>

        <p>В рамках архитектуры также предусмотрен CLI — утилита командной строки, позволяющая пользователю
            инициировать действия по установке, настройке и управлению компонентами системы. Дополнительно разработан
            инструмент сборки установочного пакета, формирующий самодостаточный архив с необходимыми контроллерами,
            зависимостями и сценариями развертывания, что обеспечивает возможность автономной установки системы в
            изолированной среде.</p>

        <figure id="arch">
            <img src="/images/arch.png">
            <figcaption>Архитектура подсистемы управления</figcaption>
        </figure>

        <p>
            В разработанной системе реализована подсистема администрирования, которая охватывает как централизованное
            управление кластером и отдельными сервисами, так и процессы первичного развертывания. Управление
            обеспечивается с помощью менеджера, агента и контроллеров, а развертывание — с помощью инструмента сборки
            установочного пакета, включающего все необходимые компоненты. Выбранная архитектура объединяет
            административные механизмы и средства развертывания в единую, автономно функционирующую технологическую
            платформу.
        </p>
    </hgroup>
    <hgroup>
        <h3 id="chapter_dev_section_dev_model">Разработка формальной модели управления сервисами и кластером</h3>

        <p>Для обеспечения детерминированного, воспроизводимого и проверяемого поведения системы, была разработана
            формальная модель, описывающая жизненный цикл управляемых сервисов, а также агрегированное состояние
            кластера СКУД. Модель состоит из двух уровней: локальной (на уровне отдельного сервиса) и глобальной (на
            уровне всей системы).</p>

        <p>Каждый управляемый сервис в системе рассматривается как конечный автомат, находящийся в одном из следующих
            состояний (см. <a class="link" href="#service_states">рисунок</a>):</p>
        <ul class="dashenum">
            <li>Зарегистрирован — сервис загружен в систему, сопровождается запущенным контроллером, но ещё не
                установлен и не активирован</li>
            <li>Установлен — сервис и все его зависимости корректно установлены на целевом устройстве</li>
            <li>Запущен — сервис активен, выполняет свою функцию и регулярно передаёт метрики агенту</li>
            <li class="last">Ошибка — контроллер перестал отвечать или аварийно завершился, сервис признан неисправным
            </li>
        </ul>

        <p>Переходы между состояниями осуществляются по дискретным операциям:</p>
        <ul class="dashenum">
            <li>Установка</li>
            <li>Запуск</li>
            <li>Остановка</li>
            <li class="last">Удаление</li>
        </ul>

        <figure id="service_states">
            <img src="/images/service_states.png">
            <figcaption>Граф состояний и переходов сервиса</figcaption>
        </figure>

        <p>Операции инициируются агентом и выполняются соответствующим контроллером. Все действия должны быть
            атомарными: при возникновении ошибки контроллер обязан вернуть сервис в исходное состояние, и агент
            корректирует соответствующие записи в базе данных.</p>

        <p>На одном устройстве агент может управлять несколькими сервисами различных типов и версий. Для каждого типа
            может быть зарегистрировано несколько версий, однако только одна из них может находиться в состоянии выше
            &quot;зарегистрирован&quot; и считается активной. Остальные версии сохраняются в пассивном состоянии
            &quot;зарегистрирован&quot;, что позволяет реализовать откат к предыдущим версиям без необходимости
            повторной загрузки
            артефактов.</p>

        <p>Для принятия решений о допустимости управляющих операций на уровне всей системы разработана модель
            агрегированного состояния кластера. Это состояние определяется на основе локальных состояний всех активных
            сервисов.</p>

        <p>В модели определяются три допустимых агрегированных состояния:</p>
        <ul class="dashenum">
            <li>Зарегистрирован — все активные сервисы находятся в состоянии <q>зарегистрирован</q></li>
            <li>Установлен — все активные сервисы находятся в состоянии <q>установлен</q></li>
            <li class="last">Запущен — все активные сервисы находятся в состоянии <q>запущен</q></li>
        </ul>

        <p>Если хотя бы один из активных сервисов находится в состоянии, не соответствующем целевому уровню
            агрегированного состояния, кластер считается неконсистентным, и выполнение операций, требующих
            согласованности, приостанавливается до восстановления корректного состояния всех сервисов.</p>

        <p>Сервисы, находящиеся в состоянии <q>ошибка</q>, считаются препятствующими достижению любого агрегированного
            состояния выше <q>зарегистрирован</q>, и переводят кластер в состояние неконсистентности. Таким образом,
            агрегированная модель подразумевает, что состояние <q>ошибка</q> исключает достижение состояний
            <q>установлен</q> и
            <q>запущен</q>.
        </p>

        <p>При оценке агрегированного состояния учитываются только активные версии сервисов, то есть такие, которые
            находятся в состоянии выше <q>зарегистрирован</q>. Все остальные (включая другие версии того же типа)
            исключаются
            из расчета.</p>

        <p>Агрегированная модель не задаёт конкретных механизмов переходов между состояниями, но служит основой для:</p>
        <ul class="dashenum">
            <li>Управления жизненным циклом кластера (развёртывание, обновление, запуск, остановка, удаление)</li>
            <li>Валидации целостности состояния перед началом выполнения сценариев</li>
            <li class="last">Корректного завершения работы сервисов перед удалением</li>
        </ul>

        <p>При этом ответственность за переходы между локальными состояниями сервисов возлагается на агента, который
            управляет запуском, остановкой и удалением контроллеров на конкретном устройстве, а также фиксирует ошибки.
            В свою очередь, менеджер координирует глобальное поведение кластера, формирует агрегированное состояние на
            основе данных от агентов и инициирует выполнение управляющих процессов. Такое разделение позволяет
            изолировать контроль исполнения и централизованное планирование, что соответствует архитектурной модели,
            описанной в <a class="link" href="#chapter_dev_section_arch">разделе</a>.</p>
    </hgroup>
    <hgroup>
        <h3 id="chapter_dev_section_dev_format">Состав установочного пакета и конфигурации топологии кластера</h3>

        <p>Для обеспечения автономного, воспроизводимого и централизованно управляемого развертывания системы в
            изолированной среде используются два взаимосвязанных формата входных артефактов: установочный пакет и
            файл конфигурации топологии кластера. Эти форматы используются совместно при запуске сценариев
            развертывания, обновления и реконфигурирования, управляемых менеджером.</p>

        <p>Установочный пакет представляет собой архив, включающий:</p>
        <ul>
            <li>манифест пакета — JSON-файл, содержащий описание всех поддерживаемых типов сервисов, ссылки на их
                контроллеры и зависимости, а также определение управляющего сценария</li>
            <li>контроллеры сервисов — исполняемые файлы, реализующие жизненный цикл конкретных типов сервисов</li>
            <li class="last">директории с зависимостями, необходимые для установки и запуска каждого сервиса</li>
        </ul>

        <p>Манифест описывает каждый тип сервиса, включая путь к его контроллеру. Упровляющий сценарий определяет
            порядок запуска типов сервисов при прямом применении, при
            обратном применении — порядок оставки.</p>

        <p>Конфигурация топологии кластера представляет собой JSON-файл, описывающий фактическое размещение сервисов на
            управляемых устройствах. Пример конфигурационного файла представлен в <a href="#app_configs">приложении</a>.
            Он включает перечень
            экземпляров сервисов, а также параметры, определяющие:</p>
        <ul class="dashenum">
            <li>тип сервиса, соответствующий одному из типов, описанных в манифесте пакета</li>
            <li>идентификатор агента, на котором должен быть размещён сервис</li>
            <li class="last">конфигурационные параметры в виде JSON-объекта, специфичные для контроллера</li>
        </ul>

        <p>Этот формат позволяет задать топологию кластера, определяя, какие сервисы и с какими параметрами должны быть
            развернуты на каждом из устройств, а также применять упровляющий сценарий агрегировано, избегая дублирования
            шагов для
            однотипных сервисов. Конфигурация передается менеджеру пользователем либо при первичном развертывании, либо
            при выполнении обновления или реконфигурирования.</p>

        <p>Манифест определяет что можно установить, а конфигурация — где и с какими параметрами это должно быть
            развернуто. Менеджер использует оба этих источника при выполнении алгоритма согласования состояния и
            упровляющиего сценария, применяя
            их в соответствии с заданной конфигурацией. Такая двухуровневая модель
            позволяет отделить описание возможностей пакета от конкретной структуры и назначения кластера, обеспечивая
            повторяемость, гибкость и возможность централизованного управления.</p>
    </hgroup>
    <hgroup>
        <h3 id="chapter_dev_section_dev_proto">Протокол обмена сообщениями</h3>

        <p>Для обеспечения надежного и компактного взаимодействия между компонентами системы был разработан
            специализированный бинарный протокол обмена сообщениями. Протокол обеспечивает строго типизированную
            передачу команд, ответов, событий и диагностических данных между менеджером, агентом и контроллерами. При
            этом он совместим с асинхронной моделью исполнения и минимизирует накладные расходы на сериализацию и
            обработку.</p>

        <p>Каждое сообщение состоит из заголовка фиксированной длины (см. <a class="link"
                href="#protocol_header">таблицу</a>) и полезной нагрузки,
            сериализованной в бинарном формате.</p>

        <table id="protocol_header">
            <caption><span>Поля заголовка протокола обмена сообщениями</span></caption>
            <thead>
                <tr>
                    <th>№</th>
                    <th>Название</th>
                    <th>Размер (байт)</th>
                    <th>Назначение</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td style="break-inside: avoid">1</td>
                    <td style="break-inside: avoid">Длина</td>
                    <td style="break-inside: avoid">4</td>
                    <td style="break-inside: avoid">Количество байт полезной нагрузки</td>
                </tr>
                <tr style="break-inside: avoid">
                    <td style="break-inside: avoid">2</td>
                    <td style="break-inside: avoid">Сессия</td>
                    <td style="break-inside: avoid">4</td>
                    <td style="break-inside: avoid">Идентификатор сессии для сопоставления запроса и ответа</td>
                </tr>
            </tbody>
        </table>
        <p>Такой формат обеспечивает точную границу сообщений в потоке: получатель сначала читает заголовок, определяет
            длину сообщения, а затем извлекает и обрабатывает его целиком. Это делает протокол устойчивым к фрагментации
            и неполному приёму, что критично при работе в асинхронной среде.</p>

        <p>Полезная нагрузка сообщения сериализуется с использованием бинарного формата Postcard, специально
            разработанного для встраиваемых систем и языка Rust. Все сообщения типизированы: каждая команда, ответ или
            событие имеет отдельный структурный тип, что упрощает обработку и снижает вероятность ошибок.</p>

        <p>Протокол поддерживает два режима передачи данных, определяемые контекстом взаимодействия:</p>
        <ul class="dashenum">
            <li>открытый режим</li>
            <li class="last">защищенный режим</li>
        </ul>

        <p>В открытом режиме передача сообщений осуществляется в незашифрованном виде. Используется для взаимодействия
            между доверенными процессами на одном устройстве.
            Безопасность обеспечивается контролем доступа к сокету со стороны операционной системы.</p>

        <p>В защищённом режиме сериализованная полезная нагрузка шифруется и каждое сообщение аутентифицируется.
            Перед началом обмена выполняется криптографическое рукопожатие по протоколу Noise Protocol Framework, в
            рамках которого стороны
            идентифицируют друг друга по заранее обменянным публичным ключам, устанавливается симметричный ключ
            шифрования с защитой от MITM-атак и формируется защищенный канал передачи.</p>

        <p>Разработанный протокол используется во всех каналах связи между:</p>
        <ul class="dashenum">
            <li>Менеджером и агентом в защищенном режиме поверх TCP</li>
            <li>Агентом и контроллером в открытом режиме поверх Unix Domain socket</li>
            <li>Агентом и CLI в открытом режиме поверх Unix Domain socket</li>
            <li class="last">Менеджером и CLI в открытом режиме поверх Unix Domain socket</li>
        </ul>

        <p>На <a href="#comm_example">рисунке</a> представлена диаграмма последовательности,
            иллюстрирующая взаимодействие компонентов системы.</p>

        <figure id="comm_example">
            <img src="/images/comm_example.png">
            <figcaption>Взаимодействие компонентов</figcaption>
        </figure>

        <p>Такой подход обеспечивает баланс между безопасностью и производительностью: шифрование применяется только при
            передаче данных по ненадежным каналам, тогда как локальные взаимодействия остаются максимально легкими.</p>

        <p>Протокол не зависит от конкретной реализации канала связи (TCP или Unix Domain socket), что обеспечивает его
            универсальность и возможность применения в любых IPC или сетевых сценариях.</p>
    </hgroup>
    <hgroup>
        <h3 id="chapter_dev_section_dev_agent">Разработка агента устройства</h3>
        <hgroup>
            <h4>Конфигурация и программные интерфейсы управления агентом</h4>
            <p>Конфигурация агента определяет параметры его функционирования, включая безопасность соединений, сетевые
                настройки и режимы сбора данных. Все параметры сохраняются в виде защищенного JSON-файла и могут быть
                изменены только через CLI. Прямое редактирование файла не предусмотрено, что обеспечивает целостность
                конфигурации и защиту от несанкционированных изменений.</p>

            <p>Конфигурация включает следующие группы параметров:</p>
            <ul class="dashenum">
                <li>параметры безопасности: публичный ключ менеджера и пара ключей агента (приватный и публичный)</li>
                <li>сетевые настройки: порт прослушивания TCP-соединений</li>
                <li>параметры сбора данных: интервалы опроса и ограничения на количество сохраняемых метрик и событий
                </li>
                <li>параметры диагностики: частота проверки доступности контроллеров</li>
                <li class="last">метаинформация: версия установленного программного обеспечения агента</li>
            </ul>

            <p>Для управления конфигурацией и получения диагностической информации используется локальный интерфейс CLI,
                реализованный через Unix domain socket. Данный интерфейс функционирует на основе протокола обмена
                сообщениями (см. <a href="#chapter_dev_section_dev_proto">раздел</a>) в открытом режиме, то есть без
                шифрования, поскольку взаимодействие
                происходит внутри одного устройства. CLI-клиент инициирует соединение, отправляет команды
                сериализованного формата и получает структурированные ответы. Через CLI также выполняется генерация
                криптографических ключей, настройка параметров сбора данных и просмотр состояния управляемых сервисов.
            </p>

            <p>Для удалённого управления агент предоставляет второй интерфейс, предназначенный для взаимодействия с
                менеджером. Этот интерфейс работает на основе протокола обмена сообщениями в защищённом режиме по
                TCP-соединению. Аутентификация сторон осуществляется на основе заранее обменённых публичных ключей.
                После установления защищённого канала менеджер может передавать команды, связанные с регистрацией и
                исключением сервисов, изменением их состояния, обновлением параметров, а также с запросами метрик и
                событий.</p>

            <p>Оба интерфейса тесно связаны с процессами, реализуемыми агентом: каждая поступающая команда вызывает
                запуск соответствующего процесса администрирования, сопровождающейся валидацией, записью в базу данных и
                при необходимости — взаимодействием с контроллером.</p>

            <p>Связь между поддерживаемыми командами обоих интерфейсов и процессами администрирования (см. <a
                    href="#agent_processes">таблицу</a>) представлена в
                <a href="#app_commands">приложении</a>.
            </p>
        </hgroup>
        <hgroup>
            <h4>Реализация процессов администрирования сервисов</h4>
            <p>
                Агент реализует совокупность процессов, обеспечивающих управление жизненным циклом сервисов, размещённых
                на управляемом устройстве. Эти процессы включают операции регистрации и исключения, перевод между
                состояниями, обновление параметров конфигурации, а также сбор диагностической информации, метрик и
                событий. В <a class="link" href="#agent_processes">таблице</a> приведён перечень поддерживаемых
                процессов, классифицированных по назначению.
            </p>

            <table id="agent_processes">
                <caption><span>Поддерживаемые процессы администрирования сервисов на стороне агента</span></caption>
                <thead>
                    <tr>
                        <th>№</th>
                        <th>Область</th>
                        <th>Наименование процесса</th>
                        <th>Назначение процесса</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>1</td>
                        <td>Управление сервисами</td>
                        <td>Регистрация сервиса</td>
                        <td>Загрузка артефактов, запуск контроллера, инициализация записей в базе данных</td>
                    </tr>
                    <tr>
                        <td>2</td>
                        <td>Управление сервисами</td>
                        <td>Исключение сервиса</td>
                        <td>Завершение контроллера, удаление файлов и записей, исключение из системы</td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>Управление сервисами</td>
                        <td>Смена состояния сервиса</td>
                        <td>Перевод сервиса между состояниями: установлен, запущен, остановлен</td>
                    </tr>
                    <tr>
                        <td>4</td>
                        <td>Управление сервисами</td>
                        <td>Обновление конфигурационных параметров</td>
                        <td>Передача новых аргументов контроллеру и фиксация изменений при успешной валидации</td>
                    </tr>
                    <tr>
                        <td>5</td>
                        <td>Мониторинг</td>
                        <td>Контроль жизнеспособности контроллера</td>
                        <td>Отслеживание активности процесса, проверка соединения, фиксация ошибок</td>
                    </tr>
                    <tr>
                        <td>6</td>
                        <td>Сбор метрик</td>
                        <td>Периодический опрос контроллеров</td>
                        <td>Получение данных о ресурсопотреблении и сохранение их в базе данных агента</td>
                    </tr>
                    <tr>
                        <td>7</td>
                        <td>Сбор метрик</td>
                        <td>Управление архивом метрик</td>
                        <td>Удаление устаревших записей при превышении лимита, определённого в конфигурации</td>
                    </tr>
                    <tr>
                        <td>8</td>
                        <td>Журналирование событий</td>
                        <td>Фиксация всех значимых операций и сбоев</td>
                        <td>Запись событий в базу данных с указанием времени, типа и причины</td>
                    </tr>
                    <tr>
                        <td>9</td>
                        <td>Диагностика</td>
                        <td>Получение текущего состояния сервисов</td>
                        <td class="last">Запрос информации о зарегистрированных сервисах</td>
                    </tr>
                </tbody>
            </table>

            <p>Перед выполнением любой операции с сервисом агент инициирует запуск соответствующего контроллера.
                Контроллер запускается как дочерний процесс и подключается к Unix-сокету агента. После установления
                соединения агент запрашивает у контроллера сведения об обслуживаемом сервисе и сопоставляет их с
                актуальными данными в своей базе. Если соединение не устанавливается в пределах заданного таймаута,
                агент рассматривает это как сбой запуска и переводит сервис в состояние «ошибка».</p>

            <p>В процессе работы контроллер сохраняет соединение с агентом. Агент передаёт команды в сериализованном
                виде, контроллер выполняет требуемую операцию и возвращает результат. Завершение отдельных операций не
                приводит к закрытию соединения — оно сохраняется активным до завершения жизненного цикла контроллера.
                При аварийном завершении контроллера или потере соединения сервис немедленно переводится в состояние
                <q>ошибка</q>, а соответствующее событие фиксируется в журнале.
            </p>

            <p>При выполнении любой операции над сервисом реализуется механизм эксклюзивного доступа. Это означает, что
                в любой момент времени может выполняться только одна операция управления конкретным сервисом. Все
                остальные процессы, связанные с этим сервисом (в том числе сбор метрик и получение состояния),
                блокируются до завершения текущего действия. Такая модель обеспечивает согласованность
                состояния и предотвращает некорректную интерпретацию результата операций.</p>

            <p>Регистрация сервиса включает загрузку артефактов, запуск контроллера и сохранение записей в базе данных.
                Допускается только при отсутствии другой активной версии того же типа. Блок-схема алгоритма регистрации
                приведена на <a href="#registration_alg">рисунке</a>.</p>

            <figure id="registration_alg">
                <img src="/images/registration_alg.png">
                <figcaption>Алгоритм регистрации сервиса</figcaption>
            </figure>
            <p>
                Исключение сервиса включает завершение работы контроллера, удаление всех связанных файлов и записей,
                исключение из локальной базы данных. Допустима только для сервисов в состоянии <q>зарегистрирован</q>.
                Блок-схема алгоритма представлена на <a href="#exclude_alg">рисунке</a>.
            </p>
            <figure id="exclude_alg">
                <img src="/images/exclude_alg.png">
                <figcaption>Алгоритм исключения сервиса</figcaption>
            </figure>
            <p>
                Смена состояния — это перевод сервиса между допустимыми состояниями модели жизненного цикла. Переход
                инициируется агентом, передаётся контроллеру, а результат операции сохраняется в базе данных. Блок-схема
                алгоритма представлена на <a class="link" href="#change_state_alg">рисунке</a>.
            </p>
            <figure id="change_state_alg">
                <img src="/images/change_state_alg.png">
                <figcaption>Алгоритм смены состояния сервиса</figcaption>
            </figure>
            <p>
                Обновление конфигурационных параметров допускается для сервисов в состоянии не выше <q>установлен</q>.
                Параметры передаются контроллеру в формате JSON, проходят валидацию, и в случае успеха фиксируются в
                базе агента. При ошибке сохраняется предыдущее значение. Блок-схема алгоритма обновления параметров
                приведена на <a class="link" href="#update_params_alg">рисунке</a>.
            </p>
            <figure id="update_params_alg">
                <img src="/images/update_params_alg.png">
                <figcaption>Алгоритм обновления конфигурационных параметров сервиса</figcaption>
            </figure>
            <p>Для оценки работоспособности и сбора статистики агент регулярно опрашивает контроллеры. Полученные
                значения метрик, включая загрузку CPU, объём потребляемой памяти и доступность сервиса, сохраняются в
                базе данных. При превышении лимита хранения, заданного в конфигурации, устаревшие записи автоматически
                удаляются. Таким образом, реализуется не только сбор, но и управление архивом метрик.</p>

            <p>Параллельно осуществляется журналирование событий. Каждая успешная или ошибочная операция сопровождается
                записью в журнал с указанием времени, типа события и описания. Журнал также очищается при превышении
                допустимого объема, определенного в конфигурации агента.</p>

            <p>Агент также предоставляет интерфейс для получения текущей информации о зарегистрированных сервисах. Этот
                интерфейс используется при диагностике состояния, а также при выполнении CLI-команд.</p>

            <p>Таким образом, реализованные процессы на стороне агента обеспечивают полную поддержку жизненного цикла
                сервисов, диагностику их состояния и устойчивость к сбоям за счет мониторинга, журналирования,
                механизмов отката и гарантированного эксклюзивного выполнения операций.</p>
        </hgroup>
        <hgroup>
            <h4>Проектирование базы данных агента</h4>

            <p>Для обеспечения надёжного хранения информации о зарегистрированных сервисах, выполняемых операциях и
                диагностических данных в агенте используется встроенная база данных на основе SQLite. База данных
                функционирует автономно, не требует отдельного сервера и обеспечивает атомарность всех операций,
                выполняемых в рамках процессов администрирования.</p>
            <p>Описание сущностей приведено в <a class="link" href="#agent_entities">таблице</a>.</p>
            <table id="agent_entities">
                <caption><span>Описание сущностей базы данных агента</span></caption>
                <thead>
                    <tr>
                        <th>№</th>
                        <th>Сущность</th>
                        <th>Описание</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>1</td>
                        <td>Сервисы</td>
                        <td>Зарегистрированные в агенте сервисы с учетом их типа и версии</td>
                    </tr>
                    <tr>
                        <td>2</td>
                        <td>Метрики</td>
                        <td>Метрики, отправляемые контроллерами управляемых сервисов</td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>Журнал событий</td>
                        <td class="last">Хронологическая последовательность событий и действий, выполнявшихся агентом и
                            контроллерами</td>
                    </tr>
                </tbody>
            </table>
            <br>
            <p>Характеристика атрибутов каждой сущности и их доменов приведена в <a
                    href="#agent_attributes">таблице</a>.</p>
            <table id="agent_attributes">
                <caption><span>Атрибуты и домены сущностей базы данных агента</span></caption>
                <thead>
                    <tr>
                        <th>№</th>
                        <th>Сущность</th>
                        <th>Атрибут</th>
                        <th>Домен</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td rowspan="6">1</td>
                        <td rowspan="6">Сервисы</td>
                        <td>Идентификатор</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Тип</td>
                        <td>Text</td>
                    </tr>
                    <tr>
                        <td>Версия</td>
                        <td>Text</td>
                    </tr>
                    <tr>
                        <td>Состояние</td>
                        <td>Text</td>
                    </tr>
                    <tr>
                        <td>Активен</td>
                        <td>Boolean</td>
                    </tr>
                    <tr>
                        <td>Конфигурация</td>
                        <td>Text</td>
                    </tr>

                    <tr>
                        <td rowspan="6">2</td>
                        <td rowspan="6">Метрики</td>
                        <td>Идентификатор</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Идентификатор сервиса</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Загрузка процессора</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Потребление памяти</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Доступность</td>
                        <td>Boolean</td>
                    </tr>
                    <tr>
                        <td>Время</td>
                        <td>Text</td>
                    </tr>

                    <tr>
                        <td rowspan="5">3</td>
                        <td rowspan="5">События</td>
                        <td>Идентификатор</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Идентификатор сервиса</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Тип события</td>
                        <td>Text</td>
                    </tr>
                    <tr>
                        <td>Описание</td>
                        <td>Text</td>
                    </tr>
                    <tr>
                        <td>Время</td>
                        <td class="last">Text</td>
                    </tr>
                </tbody>
            </table>
            <p>На рисунках <a href="#agent_er_diagram"></a> и <a href="#agent_db_diagram"></a>
                представлены логическая и физическая модели спроектированной базы данных.</p>

            <figure id="agent_er_diagram">
                <img src="/images/agent_er_diagram.png">
                <figcaption>Логическая схема базы данных агента</figcaption>
            </figure>
            <figure id="agent_db_diagram">
                <img src="/images/agent_db_diagram.png">
                <figcaption>Физическая схема базы данных агента</figcaption>
            </figure>
        </hgroup>
    </hgroup>
    <hgroup>
        <h3 id="chapter_dev_section_dev_manager">Разработка менеджера подсистемы</h3>
        <hgroup>
            <h4>Конфигурация и программные интерфейсы управления менеджером</h4>
            <p>Менеджер использует внутреннюю конфигурацию, определяющую параметры его функционирования: параметры
                безопасности, интервалы фоновых операций и лимиты хранения отчетных данных. Конфигурация сохраняется
                в
                виде защищенного JSON-файла, доступ к которому осуществляется только через CLI. Прямое
                редактирование
                файла исключено, что обеспечивает воспроизводимость поведения системы и предотвращает возможность
                нарушения целостности.</p>

            <p>Конфигурация включает:</p>
            <ul class="dashenum">
                <li>пару ключей менеджера (приватный и публичный), используемую для установления защищённых
                    соединений с
                    агентами</li>
                <li>временной интервал формирования отчётов о состоянии кластера</li>
                <li>максимальное количество сохраняемых отчётов</li>
                <li class="last">версию установленного исполняемого файла</li>
            </ul>

            <p>Для взаимодействия с управляющим модулем используется программный интерфейс, реализованный на основе
                протокола обмена сообщениями (см. <a href="#chapter_dev_section_dev_proto">раздел</a>) по Unix
                Domain socket в открытом режиме, то есть без шифрования, поскольку
                взаимодействие происходит внутри одного устройства. CLI инициирует соединение, отправляет команды
                сериализованного формата и получает структурированные ответы.</p>

            <p>Доступные через программный интерфейс действия инициируют выполнение внутренних процессов. Каждое
                действие связано с конкретной CLI командой. Связь между CLI командами и процессами (см. <a
                    href="#manager_processes">таблицу</a>) представлена в <a href="#app_commands">приложении</a>.
            </p>
        </hgroup>
        <hgroup>
            <h4>Реализация процессов администрирования кластера и управления менеджером</h4>
            <p>Менеджер реализует совокупность процессов, направленных на централизованное управление жизненным
                циклом
                компонентов системы, сбор и анализ диагностических данных, а также сопровождение собственной
                конфигурации. Эти процессы охватывают как управление состоянием распределённых сервисов, так и
                административные задачи, связанные с работой самого управляющего компонента. В <a
                    href="#manager_processes">таблице</a> приведен
                систематизированный перечень поддерживаемых процессов.</p>

            <table id="manager_processes">
                <caption><span>Поддерживаемые процессы администрирования кластера и управления менеджером</span>
                </caption>
                <thead>
                    <tr>
                        <th>№</th>
                        <th>Область</th>
                        <th>Наименование процесса</th>
                        <th>Назначение процесса</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>1</td>
                        <td>Управление кластером</td>
                        <td>Согласование топологии и конфигурации</td>
                        <td>Приведение текущего состояния кластера в соответствие с конфигурацией: установка,
                            удаление,
                            переопределение параметров и обновление сервисов</td>
                    </tr>
                    <tr>
                        <td>2</td>
                        <td>Управление кластером</td>
                        <td>Выполнение управляющего сценария</td>
                        <td>Последовательное выполнение шагов сценария запуска или остановки, определенных в
                            манифесте
                        </td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>Управление кластером</td>
                        <td>Перевод состояния сервиса</td>
                        <td>Перевод конкретного экземпляра сервиса в целевое состояние (установлен, запущен,
                            остановлен)
                        </td>
                    </tr>
                    <tr>
                        <td>4</td>
                        <td>Сбор и анализ метрик</td>
                        <td>Формирование отчета о состоянии</td>
                        <td>Агрегация статистических данных от агентов и формирование итогового отчета</td>
                    </tr>
                    <tr>
                        <td>6</td>
                        <td>Сбор и анализ событий</td>
                        <td>Получение событий от агентов</td>
                        <td>Извлечение событийной информации за заданный период</td>
                    </tr>
                    <tr>
                        <td>7</td>
                        <td>Управление менеджером</td>
                        <td>Обновление конфигурации управляющего компонента</td>
                        <td>Изменение параметров работы менеджера, включая расписание формирования отчётов и
                            параметры
                            хранения</td>
                    </tr>
                    <tr>
                        <td>8</td>
                        <td>Управление менеджером</td>
                        <td>Управление списком зарегистрированных агентов</td>
                        <td class="last">Добавление, удаление и редактирование сведений об агентах и их параметрах
                        </td>
                    </tr>
                </tbody>
            </table>

            <p>После выполнения указанных процессов, особенно в рамках согласования топологии и конфигурации,
                менеджер
                фиксирует актуальное агрегированное состояние системы и обновляет локальную базу данных. При
                необходимости пользователь может инициировать выполнение управляющего сценария.</p>

            <p>В отличие от запуска и остановки, основанные на одном упровляющем сценарии,
                процессы установки, обновления и реконфигурации выполняются исключительно в рамках согласования
                топологии. При этом сервисы устанавливаются в порядке, заданном в конфигурации кластера, без
                необходимости явного задания шагов.</p>

            <p>Далее последовательно описаны ключевые процессы, реализованные на стороне менеджера, включая алгоритм
                согласования топологии и выполнение управляющих сценариев.</p>

            <p>Перед выполнением любого административного действия менеджер инициирует соединение с агентами,
                зарегистрированными в системе. Соединение устанавливается по протоколу передачи сообщений в защищенном
                режиме, а сведения об актуальности агентов и их параметрах извлекаются из локальной базы данных.</p>

            <p>Ключевым процессом является согласование топологии кластера. Этот процесс используется как при
                первичном
                развертывании, так и при последующем обновлении или реконфигурации системы. Его целью является
                приведение фактического состояния распределенных сервисов в соответствие с конфигурацией кластера.
            </p>

            <p>Алгоритму синхронизации топологии на вход подяется следующая информация:</p>
            <ul class="dashenum">
                <li>актуальное состояние кластера из базы данных менеджера</li>
                <li>описание целевого состояния кластера из конфигурационного файла</li>
                <li class="last">при необходимости — манифест установочного пакета</li>
            </ul>

            <p>Алгоритм согласования включает следующие этапы:</p>
            <ul class="dashenum">
                <li>анализ различий между текущим и целевым состоянием кластера, выявление новых, изменённых и
                    устаревших сервисов</li>
                <li>подготовка среды: установка новых сервисов, обновление параметров, перевод устаревших
                    экземпляров в
                    неактивное состояние</li>
                <li>очистка: удаление сервисов, не включенных в новую конфигурацию, и очистка соответствующих данных
                </li>
                <li class="last">фиксация нового состояния кластера в базе данных</li>
            </ul>

            <p>Блок-схема алгоритма согласования топологии представлена на <a class="link"
                    href="#sync_cluster_topology_alg">рисунке</a>.</p>

            <figure id="sync_cluster_topology_alg">
                <img src="/images/sync_cluster_topology_alg.png">
                <figcaption>Алгоритм согласования топологии кластера</figcaption>
            </figure>

            <p>Управляющий сценарий, описанный в манифесте, выполняется по следующему алгоритму:</p>
            <ul class="dashenum">
                <li>определение списка агентов и сервисов, затронутых текущим шагом</li>
                <li>передачу управляющих инструкций агентам</li>
                <li>сбор результатов выполнения и обновление базы данных</li>
                <li class="last">обработку ошибок</li>
            </ul>
            <p> Выполнение шага считается успешным, если все целевые сервисы достигли заданного состояния.
                При возникновении ошибок инициируется процесс отката: ранее примененные шаги отменяются, а затронутые
                сервисы возвращаются в исходное состояние. В зависимости от цели запуска упровляющиего сценария шаги
                выполняются в различном порядке: для запуска по описанному в манифесте, для остановки — в
                обратном.</p>

            <p>Помимо операций, связанных с жизненным циклом сервисов, менеджер периодически или по запросу
                инициирует
                сбор статистических данных и формирование аналитических отчетов. Для этого осуществляется
                последовательное подключение к агентам, извлечение агрегированных метрик и событий за заданный
                интервал
                времени, последующая агрегация данных и сохранение отчётов в локальной базе.</p>

            <p>Аналогично осуществляется анализ событий, поступающих от агентов, с целью восстановления хронологии
                изменений в системе и диагностики причин возможных отклонений.</p>

            <p>В дополнение к основным функциям, менеджер реализует вспомогательные процессы управления собственной
                конфигурацией и списком зарегистрированных агентов. Пользователь может изменять параметры работы
                управляющего компонента, описанные ранее.</p>

            <p>Управление списком агентов включает:</p>
            <ul class="dashenum">
                <li>добавление новых устройств с указанием адреса и публичного ключа</li>
                <li class="last">удаление недоступных или устаревших узлов</li>
            </ul>

            <p>При работе с метриками система поддерживает не только формирование текущих отчетов, но и ведение
                архива
                статистических данных. Объём сохраняемой информации регулируется установленными лимитами. При
                превышении
                заданного предела наиболее старые записи автоматически удаляются, что обеспечивает устойчивость
                системы
                при длительной эксплуатации и ограниченных ресурсах хранения.</p>

            <p>Таким образом, процессы, реализованные в менеджере, обеспечивают централизованное, воспроизводимое и
                надёжное управление состоянием кластера СКУД на основе единой модели согласования и строго
                определенных
                управляющих сценариев.</p>
        </hgroup>
        <hgroup>
            <h4>Проектирование базы данных менеджера</h4>

            <p>
                Для обеспечения согласованного управления кластером, хранения актуального состояния сервисов,
                поддержки
                сценариев и формирования отчётов, была спроектирована встроенная база данных менеджера. В качестве
                системы управления базами данных выбрана SQLite, что позволило обеспечить атомарность операций,
                устойчивость к сбоям, простоту интеграции и переносимости, а также достаточную производительность
                для
                задач управления кластером СКУД.
            </p>
            <p>
                Описание сущностей спроектированной базы данных приведено в <a href="#manager_entities">таблице</a>.
            </p>
            <table id="manager_entities">
                <caption><span>Определение сущностей базы данных менеджера</span></caption>
                <thead>
                    <tr>
                        <th>№</th>
                        <th>Сущность</th>
                        <th>Описание</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>1</td>
                        <td>Агенты</td>
                        <td>Зарегистрированные в системе агенты и их параметры соединения</td>
                    </tr>
                    <tr>
                        <td>2</td>
                        <td>Типы сервисов</td>
                        <td>Типы сервисов кластера</td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>Сервисы</td>
                        <td>Сервисы, установленные на каждом агенте</td>
                    </tr>
                    <tr>
                        <td>4</td>
                        <td>Шаги сценариев</td>
                        <td>Шагов сценариев управления</td>
                    </tr>
                    <tr>
                        <td>5</td>
                        <td>Сценарии</td>
                        <td>Сценарии управления жизненным циклом кластера: запуск, остановка, удаление</td>
                    </tr>
                    <tr>
                        <td>6</td>
                        <td>Статистика</td>
                        <td>Сводные агрегированные значения метрик от сервисов</td>
                    </tr>
                    <tr>
                        <td>7</td>
                        <td>Отчёты</td>
                        <td>Агрегированные отчеты о состоянии кластера</td>
                    </tr>
                </tbody>
            </table>
            <p>
                Характеристика атрибутов каждой сущности и их доменов приведена в <a class="link"
                    href="#manager_attributes">таблице</a>.
            </p>
            <table id="manager_attributes">
                <caption><span>Атрибуты и домены сущностей базы данных менеджера</span></caption>
                <thead>
                    <tr>
                        <th>№</th>
                        <th>Сущность</th>
                        <th>Атрибут</th>
                        <th>Домен</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td rowspan="5">1</td>
                        <td rowspan="5">Агенты</td>
                        <td>Идентификатор</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Имя</td>
                        <td>Text</td>
                    </tr>
                    <tr>
                        <td>Сокет</td>
                        <td>Text</td>
                    </tr>
                    <tr>
                        <td>Публичный ключ</td>
                        <td>Text</td>
                    </tr>
                    <tr>
                        <td>Время регистрации</td>
                        <td>Text</td>
                    </tr>

                    <tr>
                        <td rowspan="2">2</td>
                        <td rowspan="2">Типы сервисов</td>
                        <td>Идентификатор</td>
                        <td>Text</td>
                    </tr>
                    <tr>
                        <td>Название</td>
                        <td>Text</td>
                    </tr>

                    <tr>
                        <td rowspan="4">3</td>
                        <td rowspan="4">Сервисы</td>
                        <td>Идентификатор</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Идентификатор типа</td>
                        <td>Text</td>
                    </tr>
                    <tr>
                        <td>Идентификатор агента</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Версия</td>
                        <td>Text</td>
                    </tr>

                    <tr>
                        <td rowspan="2">4</td>
                        <td rowspan="2">Сценарии</td>
                        <td>Идентификатор</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Название</td>
                        <td>Text</td>
                    </tr>

                    <tr>
                        <td rowspan="4">5</td>
                        <td rowspan="4">Шаги сценариев</td>
                        <td>Идентификатор</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Идентификатор сценария</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Порядковый номер</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Тип сервиса</td>
                        <td>Text</td>
                    </tr>

                    <tr>
                        <td rowspan="2">6</td>
                        <td rowspan="2">Отчёты</td>
                        <td>Идентификатор</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Время создания</td>
                        <td>Text</td>
                    </tr>

                    <tr>
                        <td rowspan="7">7</td>
                        <td rowspan="7">Статистика</td>
                        <td>Идентификатор</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Идентификатор отчета</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Идентификатор сервиса</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>средняя загрузка процессора</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>среднее потребление памяти</td>
                        <td>Integer</td>
                    </tr>
                    <tr>
                        <td>Доступность</td>
                        <td>Boolean</td>
                    </tr>
                    <tr>
                        <td>Временной интервал</td>
                        <td>Text</td>
                    </tr>
                </tbody>
            </table>

            <p>На рисунке <a href="#manager_er_diagram"></a> и <a href="#manager_db_diagram"></a> представлены
                логическая и физическая
                модели
                спроектированной базы
                данных.</p>

            <figure id="manager_er_diagram">
                <img src="/images/manager_er_diagram.png">
                <figcaption>Логическая схема базы данных менеджера</figcaption>
            </figure>

            <figure id="manager_db_diagram">
                <img src="/images/manager_db_diagram.png">
                <figcaption>Физическая схема базы данных менеджера</figcaption>
            </figure>
        </hgroup>
    </hgroup>
    <hgroup>
        <h3 style="break-before:page" id="chapter_dev_section_dev_cli">Разработка CLI</h3>
        <hgroup>
            <h4>Взаимодействие с агентом и менеджером</h4>
            <p>CLI позволяет инициировать административные процессы, реализуемые на стороне агента и менеджера.
                Взаимодействие осуществляется через программные интерфейсы, реализованные компонентами системы, на
                основе Unix domain сокетов. Обмен сообщениями выполняется с использованием протокола обмена сообщениями
                (см. <a href="#chapter_dev_section_dev_proto">раздел</a>): каждая команда сериализуется и передаётся в
                соответствующий компонент, после чего CLI
                получает структурированный ответ с результатом выполнения операции.</p>

            <p>Помимо вызова процессов управления системой, CLI также реализует процессы администрирования самих
                компонентов — агента и менеджера. Команды, инициирующие выполнение указанных процессов, приведены в <a
                    href="#app_commands">приложении</a>, где отображено соответствие между команда CLI и
                выполняемыми действиями.
            </p>
        </hgroup>
        <hgroup>
            <h4>Реализация процессов администрирования агента и менеджера</h4>
            <p>Процессы администрирования агентов и менеджера включают установку, обновление и удаление соответствующих
                компонентов.</p>

            <p>Установка компонента осуществляется путём копирования исполняемого файла, включённого в состав CLI, в
                целевую директорию, создания начального конфигурационного файла и регистрации системной службы,
                обеспечивающей автоматический запуск компонента при загрузке устройства. По завершении установки агент
                или менеджер становятся активными и готовы к приёму управляющих команд.</p>

            <p>Обновление компонента представляет собой замену текущего исполняемого файла на более новую версию, если
                таковая содержится в составе CLI. Сравнение версий осуществляется на основе информации, хранящейся в
                конфигурации компонента. Обновление сопровождается остановкой службы, заменой бинарного файла и
                последующим перезапуском. При необходимости выполняется миграция базы данных компонента, позволяющая
                сохранить все накопленные данные и настройки. Такой подход обеспечивает бесшовный переход между версиями
                без нарушения функционирования системы и без потери состояния.</p>

            <p>Удаление агента или менеджера допускается только при условии, что это не нарушит целостность управляемой
                системы. В частности, удаление агента возможно только в случае отсутствия активных зарегистрированных
                сервисов на устройстве, а удаление менеджера — при отсутствии сервисов, управление которыми зависит от
                него. В процессе удаления CLI завершает соответствующую службу, удаляет исполняемый файл,
                конфигурационные данные и прочие связанные артефакты, включая, при необходимости, установочный пакет,
                ранее развёрнутый менеджером. Удаление выполняется полностью и не требует дополнительной очистки
                вручную.</p>
        </hgroup>
    </hgroup>
    <hgroup>
        <h3 id="chapter_dev_section_dev_controller">Разработка контроллеров сервисов и инструмента сборки установочного
            пакета
        </h3>
        <hgroup>
            <h4>Архитектура и программный интерфейс контроллеров сервисов</h4>
            <p>Контроллеры реализуют жизненный цикл управляемых сервисов, таких как API-сервер, веб-сервер
                или СУБД. Каждый контроллер разрабатывается как отдельный исполняемый файл и запускается агентом в
                качестве дочернего процесса при регистрации или переходе состояния сервиса. Взаимодействие между агентом
                и контроллером осуществляется по протоколу обмена сообщениями (см. <a
                    href="#chapter_dev_section_dev_proto">раздел</a>) в открытом режиме через Unix
                domain socket.</p>

            <p>Также, контроллеры реализуют строго типизированный программный интерфейс, обеспечивающий
                детерминированное выполнение операций. Все команды, передаваемые агентом, сериализуются в типизированную
                структуру, обрабатываются контроллером, и сопровождаются формированием соответствующего
                структурированного ответа. Такой подход позволяет гарантировать корректность взаимодействия и исключает
                неоднозначность интерпретации команд.</p>

            <p>Архитектура контроллера включает два уровня:</p>
            <ul class="dashenum">
                <li>внешний программный интерфейс — приём и обработка команд от агента через сокет</li>
                <li class="last">внутренний программный интерфейс — реализация прикладной логики установки, запуска,
                    остановки и удаления конкретного сервиса</li>
            </ul>

            <p>Обязательный набор операций, реализуемых каждым контроллером:</p>
            <ul class="dashenum">
                <li>получение сведений об обслуживаемом сервисе</li>
                <li>установка сервиса и всех его зависимостей</li>
                <li>запуск и остановка сервиса</li>
                <li>удаление установленных данных</li>
                <li>сбор статистики (ресурсоёмкость, доступность)</li>
                <li class="last">обновление конфигурационных параметров</li>
            </ul>

            <p>Каждая операция выполняется атомарно: при возникновении ошибки контроллер обязан вернуть систему в
                предыдущее устойчивое состояние и сформировать диагностическое сообщение. Все команды, полученные
                контроллером, валидируются и сопоставляются с допустимыми в текущем состоянии. Операции обновления
                конфигурации допускаются только в состояниях, не выше "установлен".</p>

            <p>Конфигурационные параметры передаются контроллеру в виде JSON-объекта. Контроллер производит
                синтаксический и логический разбор параметров, выполняет валидацию значений и, в случае успеха,
                применяет конфигурацию. При наличии ошибок формируется соответствующее сообщение, а предыдущая
                конфигурация сохраняется без изменений.</p>

            <p>Для диагностики и фиксации неисправностей контроллер обязан возвращать четкие и воспроизводимые сообщения
                об ошибках. Эти сообщения обрабатываются агентом, записываются в журнал событий и могут инициировать
                откат или смену состояния сервиса.</p>

            <p>На <a class="link" href="#controller_arch">рисунке</a> представлена UML-диаграмма, иллюстрирующая
                архитектуру контроллера, набор реализуемых
                операций и взаимодействие с агентом.</p>

            <figure id="controller_arch">
                <img src="/images/controller_arch.png">
                <figcaption>Архитектура контроллера</figcaption>
            </figure>

            <p>
                Таким образом, унифицированная архитектура и программный интерфейс контроллеров обеспечивают
                согласованное поведение всех типов сервисов, минимизируют риски сбоев и упрощают реализацию инструментов
                развертывания.
            </p>
        </hgroup>
        <hgroup>
            <h4>Разработка контроллеров PostgreSQL, API-сервера и Web-сервера</h4>
            <p>В рамках кластера СКУД были разработаны контроллеры для трёх основных типов сервисов: сервера
                базы данных PostgreSQL, серверной части API и веб-сервера.</p>

            <p>Контроллер PostgreSQL обеспечивает установку, настройку и управление экземпляром PostgreSQL 16,
                используемого в качестве базы данных API-сервера. Установка производится с использованием deb-пакетов,
                включенных в установочный пакет, без обращения к внешним репозиториям. В процессе установки выполняется
                настройка pg_hba.conf, создание пользователя и базы данных.</p>

            <p>Жизненный цикл сервиса реализуется через systemd: при запуске и остановке PostgreSQL используется
                соответствующая служба. Для удаления выполняется деинсталляция пакетов и очистка пользовательских
                данных. Статистика собирается путем анализа активности PostgreSQL порта и мониторинга ресурсов,
                потребляемых процессами postgres.</p>

            <p>Контроллер API-сервера управляет установкой ASP.NET Core приложения, реализующего бизнес-логику СКУД.
                Приложение поставляется в виде самостоятельного бинарного файла с включенным runtime и утилитой для
                применения миграций. В процессе установки:</p>

            <ul class="dashenum">
                <li>распаковываются исполняемые файлы</li>
                <li>применяются миграции к базе данных</li>
                <li class="last">создаётся systemd-служба с передачей строки подключения и порта</li>
            </ul>

            <p>Запуск и остановка API-сервера производятся через systemd. При необходимости порт открывается через
                iptables при запуске и закрывается при остановке. Удаление включает удаление бинарных файлов, службы и
                правил iptables. Контроллер собирает данные о потреблении ресурсов и доступности сервиса по порту.</p>

            <p>Контроллер Web-сервера управляет установкой и настройкой Nginx для проксирования запросов к API-серверу и
                раздачи клиентской части. Установка включает установку пакетов Nginx, развертывание статических файлов и
                генерацию конфигурации сайта.</p>

            <p>Запуск и остановка реализуются через включение и выключение символических ссылок в sites-enabled и
                управление iptables. Удаление включает деинсталляцию Nginx, удаление конфигурации и клиентских файлов.
                Статистика включает проверку активности порта и мониторинг процессов Nginx.</p>

            <p>Настройка работы контроллеров реализована с помощью конфигурационных параметров, представленных в
                <a href="#app_configs">приложении</a>.
            </p>
        </hgroup>
        <hgroup>
            <h4>Сборка установочного пакета и формирование сценариев развертывания</h4>
            <p>Был разработан инструмент, позволяющий формировать установочный пакет, включающий разработанные
                контроллеры сервисов, их зависимости и описание сценариев жизненного цикла.</p>

            <p>Процесс формирования установочного пакета включает два этапа: извлечение зависимостей системных пакетов и
                сборка собственных контроллеров и файлов конфигурации.</p>

            <p>Для получения полного списка бинарных зависимостей debian-пакетов (например, PostgreSQL и Nginx)
                используется виртуализированная среда на основе LXC, полностью симулирующие целевую среду. В рамках
                изолированного контейнера производится
                установка целевого пакета, после чего анализируются изменения в списке установленных компонентов.
                Полученные зависимости копируются на хост и добавляются в структуру установочного пакета. Такой подход
                обеспечивает полную автономность установки без обращения к внешним зеркалам и гарантирует
                предсказуемость окружения.</p>

            <p>После извлечения зависимостей осуществляется упаковка всех компонентов в единый архив. Структура пакета
                включает следующие элементы:</p>
            <ul class="dashenum">
                <li>директории “postgresql”, “web_server”, “api_server”, содержащие зависимости соответствующих сервисов
                </li>
                <li>исполняемые файлы контроллеров</li>
                <li>статические ресурсы клиентской части</li>
                <li>утилиты для применения миграций</li>
                <li class="last">файл manifest.json, содержащий описание типов сервисов, реализацию управляющего
                    сценария жизненным циклом кластера
                    и пути к контроллерам
                </li>
            </ul>

            <p>В <a class="link" href="#acs_scenario">таблице</a> приведено описание реализованного сценария
                управления жизненным циклом кластера.</p>

            <table id="acs_scenario">
                <caption><span>Реализованный сценарий управления жизненным циклом кластера</span></caption>
                <thead>
                    <tr>
                        <th>Порядок</th>
                        <th>Шаги</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>1</td>
                        <td>Запуск PostgreSQL</td>
                    </tr>
                    <tr>
                        <td>2</td>
                        <td>Запуск API-сервера</td>
                    </tr>
                    <tr>
                        <td>3</td>
                        <td>Запуск Web-сервера</td>
                    </tr>
                </tbody>
            </table>

            <p>
                Таким образом, разработанный инструмент позволяет сформировать полнофункциональный установочный пакет,
                пригодный для развертывания в условиях полной изоляции.
            </p>
        </hgroup>
    </hgroup>
    <hgroup>
        <h3 id="chapter_dev_section_test">Тестирование работоспособности программного обеспечения</h3>
        <hgroup>
            <h4>Цели и методика тестирования</h4>
            <p>C целью проверки полноты реализации заявленного функционала, подтверждения
                корректности взаимодействия между модулями и соответствия поведения системы проектной архитектуре было
                проведено тестирование.
                Особое внимание было уделено поддержке предсказуемых переходов между состояниями компонентов и
                возможности
                пошагового управления жизненным циклом сервисов.</p>

            <p>В рамках тестирования использовалась модель развёртывания, приведённая в <a
                    href="#app_configs">приложении</a>. Согласно данной
                топологии, программное обеспечение устанавливалось на два условных узла: db_node и backend_node. Узел
                db_node выполнял роль сервера баз данных, а backend_node одновременно использовался для размещения
                управляющего модуля (менеджера) и второго агента. Каждому агенту и менеджеру соответствовал отдельный
                пользователь, от
                имени которого
                происходило выполнение CLI команд.</p>

            <p>Проверка работы осуществлялась посредством выполнения последовательности команд в терминальной среде,
                моделирующей сценарии развертывания, управления и удаления сервисов. Все действия сопровождались
                фиксированным выводом на основе спецификации интерфейса командной строки, соответствующим ожидаемому
                поведению работающей системы. Результаты выполнения команд приведены в виде скриншотов, включенных
                в состав текущей главы.</p>

            <p>Тестирование охватывало полный жизненный цикл сервисов: от установки и конфигурации агентов до запуска,
                мониторинга, остановки и удаления установленных компонентов. Реализованная утилита командной строки
                позволила
                наглядно продемонстрировать как инициализацию инфраструктуры, так и корректную обработку изменений
                конфигурации в условиях статичной топологии.</p>
        </hgroup>
        <hgroup>
            <h4>Проведение тестирование по жизненному циклу кластера</h4>
            <p>Тестирование проводилось в виде последовательного выполнения команд, соответствующих сценарию
                развертывания из руковододства пользователя (см. <a href="#app_user_manual">приложение</a>) и
                эксплуатации системы. Далее приведено описание этапов, охватывающих весь жизненный цикл
                компонентов.</p>

            <p>На первом этапе была произведена установка управляющего модуля на узле <q>backend_node</q>. Команда
                установки
                скопировала исполняемый файл и произвела регистрацию системного сервиса, что подтверждается
                выводом сообщения об успешной установке (см. <a href="#manager_register_fig">рисунок</a>). Затем была
                выполнена генерация пары ключей. Открытый ключ необходим для настройки агентов (см.<a
                    href="#manager_configure_fig">рисунок</a>).</p>
            <figure id="manager_register_fig">
                <img src="/images/manager_register_fig.png">
                <figcaption>Установка менеджера</figcaption>
            </figure>
            <figure id="manager_configure_fig">
                <img src="/images/manager_configure_fig.png">
                <figcaption>Настройка менеджера</figcaption>
            </figure>

            <p>Далее была осуществлена установка агентов на каждом из узлов. Агент <q>db_node</q> был настраен с
                передачей
                ключа менеджера и указанием флага открытия порта для входящих соединений (см. <a
                    href="#db_node_configure_fig">рисунок</a>), в то время как
                агент <q>backend_node</q> был сконфигурирован без открытия порта (см. <a
                    href="#backend_node_configure_fig">рисунок</a>). После настройки ключей и
                параметров соединения, агенты были зарегистрированы в менеджере. При этом указывались сведения о сетевом
                адресе, порте и открытом ключе каждого из агентов (см. рисунки <a href="#register_db_node_fig"></a> и <a
                    href="#register_backend_node_fig"></a>).</p>
            <figure id="db_node_configure_fig">
                <img src="/images/db_node_configure_fig.png">
                <figcaption>Установка и настройка агента <q>db_node</q></figcaption>
            </figure>
            <figure id="backend_node_configure_fig">
                <img src="/images/backend_node_configure_fig.png">
                <figcaption>Установка и настройка агента <q>backend_node</q></figcaption>
            </figure>
            <figure id="register_db_node_fig">
                <img src="/images/register_db_node_fig.png">
                <figcaption>Регистрация агента <q>db_node</q></figcaption>
            </figure>
            <figure id="register_backend_node_fig">
                <img src="/images/register_backend_node_fig.png">
                <figcaption>Регистрация агента <q>backend_node</q></figcaption>
            </figure>

            <p>Следующим шагом была выполнена синхронизация кластера с конфигурацией, содержащей три сервиса. До начала
                установки менеджер удостоверился, что кластер находится в состоянии <q>установлен</q>. После этого была
                осуществлена
                регистрация сервисов на агентах и пошаговая установка каждого из них (см. <a
                    href="#sync_topology_fig">рисунок</a>). В результате
                выполненной операции, командой <q>cluster show</q> была отображена актуальная топология, включая
                перечень агентов с их IP-адресами, портами, а также полным списком сервисов с указанием версий (см. <a
                    href="#show_cluster_fig">рисунок</a>).</p>
            <figure id="sync_topology_fig">
                <img src="/images/sync_topology_fig.png">
                <figcaption>Развертывание кластера</figcaption>
            </figure>
            <figure id="show_cluster_fig">
                <img src="/images/show_cluster_fig.png">
                <figcaption>Топология кластера после развертывния</figcaption>
            </figure>

            <p>Для запуска кластера была вызвана команда <q>cluster start</q>. Менеджер выполнил запуск в соответствии с
                логикой, заложенной
                в упровляющем сценарии: сначала база данных, затем API-сервер, и в завершение — веб-интерфейс (см. <a
                    href="#start_cluster_fig">рисунок</a>).
                После запуска сервисов была вызвана команда <q>events</q>, фиксирующая события в
                процессе
                инициализации и запуска (см. <a href="#events_fig">рисунок</a>).</p>
            <figure id="start_cluster_fig">
                <img src="/images/start_cluster_fig.png">
                <figcaption>Запуск ластера</figcaption>
            </figure>
            <figure id="events_fig">
                <img src="/images/events_fig.png">
                <figcaption>Просмотр событий</figcaption>
            </figure>

            <p>Далее был сформирован отчёт по собранным метрикам. Команда <q>report</q> инициировала
                агрегацию
                данных от агентов, а команда <q>reports</q> позволила просмотреть сохранённые отчёты с усреднёнными
                значениями
                загрузки процессора и потребления памяти по каждому сервису (см. рисунки <a
                    href="#create_report_fig"></a> и <a href="#see_reports_fig"></a>).</p>
            <figure id="create_report_fig">
                <img src="/images/create_report_fig.png">
                <figcaption>Создание отчета</figcaption>
            </figure>
            <figure id="see_reports_fig">
                <img src="/images/see_reports_fig.png">
                <figcaption>Просмотр отчета</figcaption>
            </figure>

            <p>Затем система была переведена в состояние остановки, за счет вызова команды <q>cluster stop</q>, в ходе
                которого
                сервисы завершили работу в обратном по отношению к запуску порядке (<a
                    href="#stop_cluster_fig">рисунок</a>). После успешной остановки была выполнена
                повторная синхронизация с новой конфигурацией, не содержащей ни одного сервиса. До удаления менеджер
                проверил
                текущее состояние на соответствию состоянию <q>остановлен</q>. Далее произошло исключение и удаление
                сервисов на
                агентах (см. <a href="#delete_cluster_fig">рисунок</a>). В завершение, командой <q>cluster show</q>
                была подтверждена очистка кластера — вывод содержал сведения об
                агентах без установленных сервисов, с актуальными портами и адресами (см. <a
                    href="#cleared_cluster_show_fig">рисунок</a>).</p>
            <figure id="stop_cluster_fig">
                <img src="/images/stop_cluster_fig.png">
                <figcaption>Остановка кластера</figcaption>
            </figure>
            <figure id="delete_cluster_fig">
                <img src="/images/delete_cluster_fig.png">
                <figcaption>Удаление кластера</figcaption>
            </figure>
            <figure id="cleared_cluster_show_fig">
                <img src="/images/cleared_cluster_show_fig.png">
                <figcaption>Топология кластера после удаления</figcaption>
            </figure>

            <p>Таким образом, проведённое тестирование подтвердило корректность выполнения процессов жизненного цикла
                сервисов, соответствие утилиты командной строки ожидаемому поведению, а также целостность логики
                распределения и
                контроля состояния сервисов в системе.</p>
        </hgroup>
    </hgroup>
</hgroup>